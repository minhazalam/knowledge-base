# 🧠 Data Engineering Knowledge Base

Welcome to the **Data Engineering Knowledge Base** – your one-stop resource to master the core skills required for modern data engineering roles. This repository is built to help learners, job seekers, and professionals sharpen their technical expertise in:

- **Python for Data Engineering**
- **SQL for Analytics & Pipelines**
- **PySpark for Big Data Processing**
- **Azure Data Services (e.g., Data Factory, Data Lake, Synapse, Databricks)**
- **Interview Questions & Preparation Guide**

---

## 📚 Repository Structure


---

## 🔧 Technologies Covered

### 🐍 Python
- File handling, data structures
- Working with APIs
- Pandas for ETL
- Logging and error handling in pipelines

### 🧮 SQL
- Subqueries, joins, CTEs
- Window functions and aggregations
- Query performance tuning

### 🔥 PySpark
- RDDs vs DataFrames
- Joins and aggregations
- UDFs and performance best practices

### ☁️ Azure
- Azure Data Factory pipelines
- Azure Data Lake Gen2 structure
- Azure Synapse integration
- Azure Databricks notebooks

---

## 💼 Interview Preparation

Inside the `interview-questions/` directory, you'll find curated and regularly updated questions categorized by topic. These include:

- Conceptual questions
- Scenario-based problem solving
- Coding challenges (especially in SQL and PySpark)
- System design questions for data pipelines

---

## 🛠️ How to Use

1. Clone the repo:
   ```bash
   git clone https://github.com/<your-username>/data-engineering-knowledge-base.git


Navigate into any folder and explore markdown files or scripts.

Contributions and discussions are welcome! See below on how to contribute.

🙌 Contribution Guidelines
Want to contribute? Great!

- Fork the repo and create a feature branch.

- Add content with proper formatting.

- Make sure your changes are relevant and accurate.

- Submit a pull request with a short description.